{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary code for paper submission: 'Tracing Semantic Variation in Slang'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the supplementary data pre-processing code for 'Tracing Semantic Variation in Slang'. Since we cannot publically release all entries from Green's Dictionary of Slang (GDoS) due to copyright terms, this note book illustrates how we pre-process raw data obtained from https://greensdictofslang.com/ and turn the data into a format that can be used to reproduce our experimental results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list of non-standard Python packages you'll need. All of which can be obtained using *pip install*.\n",
    "\n",
    "- numpy\n",
    "- bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import pickle\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import GSD_Definition, GSD_Word\n",
    "from process import process_GSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration, we include the raw html dumps for 3 dictionary entries for the slang word *beast*. Each file is named after its hash tag organized by the original dictionary. The original entries can be found on the following webpages:\n",
    "\n",
    "https://greensdictofslang.com/entry/23sqfua\n",
    "\n",
    "https://greensdictofslang.com/entry/xzzdtua\n",
    "\n",
    "https://greensdictofslang.com/entry/3e7vqxq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We not first crawl our directory for these hash tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_hash = [s[:-5] for s in glob.glob('*.html')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xzzdtua', '3e7vqxq', '23sqfua']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pre-processing function will then take in a list of hash tags and process the respective html files. A pickle file will be generated for each word entry. Note that we do not collapse homonyms (i.e. same word form with multiple word entries) until the actual experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 17.84it/s, d_count=20, w_count=3]\n"
     ]
    }
   ],
   "source": [
    "process_GSD(word_hash, input_dir = \"\", output_dir = \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should generate 3 pickle files which we now load for further pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [pickle.load(open(h+'.pickle', 'rb')) for h in word_hash]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code filters the reference entries according to the set of regions that we are interested in (in our case, US and UK). It also tries to automatically extract valid example usage sentences from the reference entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['[US]', '[UK]']\n",
    "#regions = ['[US]', '[UK]', '[Aus]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1552.49it/s]\n"
     ]
    }
   ],
   "source": [
    "punctuations = '!\\'\"#$%&()\\*\\+,-\\./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "re_punc = re.compile(r\"[\"+punctuations+r\"]+\")\n",
    "re_space = re.compile(r\" +\")\n",
    "\n",
    "re_extract_quote = re.compile(r\"[1-9/]+:\")\n",
    "re_extract_quote_all = re.compile(r\"[1-9/]+:.*$\")\n",
    "\n",
    "def proc_quote_sent(sent):\n",
    "    return re_extract_quote.sub(' ', re_extract_quote_all.findall(sent)[0]).strip()\n",
    "\n",
    "def validate_quote_sent(word, sent):\n",
    "    tokens = [s.lower() for s in re_space.sub(' ', re_punc.sub('', sent)).split(' ')]\n",
    "    return word.lower() in tokens\n",
    "\n",
    "data_proc = []\n",
    "\n",
    "for i in trange(len(data)):\n",
    "    w = data[i]\n",
    "    if w.is_abbr():\n",
    "        continue\n",
    "    d_list = []\n",
    "    for d in w.definitions:\n",
    "        stamps = d.stamps\n",
    "        region_set = set([s[1] for s in stamps])\n",
    "        if np.any([r in region_set for r in regions]):\n",
    "            new_stamps = [s for s in stamps if np.any([r==s[1] in region_set for r in regions])]\n",
    "            new_def = GSD_Definition(d.def_sent)\n",
    "            new_def.stamps = new_stamps\n",
    "            new_def.contexts = {key:value for key, value in d.contexts.items() if key in new_stamps}\n",
    "            d_list.append(new_def)\n",
    "    if len(d_list) > 0:\n",
    "        new_word = GSD_Word(w.word.replace(\"\\\\xe2\\\\x80\\\\x99\", \"'\").replace(\"\\\\xe2\\\\x80\\\\x98\", \"'\"), w.pos, w.homonym)\n",
    "        new_word.definitions = d_list\n",
    "        data_proc.append(new_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the data looks after after pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WORD]\n",
      "beast\n",
      "[POS]\n",
      "adj.\n",
      "[DEFINITIONS]\n",
      "a general intensifier, both positive and negative\n",
      "1734 - [UK]\n",
      "1956 - [UK]\n",
      "white; pertaining to white culture\n",
      "1999 - [UK] - I dont want no beast food.\n",
      "excellent\n",
      "1997 - [US]\n",
      "\n",
      "[WORD]\n",
      "beast\n",
      "[POS]\n",
      "v.\n",
      "[DEFINITIONS]\n",
      "to molest a child\n",
      "1994 - [UK]\n",
      "2012 - [UK]\n",
      "to subject to physical abuse\n",
      "2005 - [UK]\n",
      "2018 - [UK]\n",
      "\n",
      "[WORD]\n",
      "beast\n",
      "[POS]\n",
      "n.\n",
      "[DEFINITIONS]\n",
      "an unpopular or unpleasant person\n",
      "1577 - [UK]\n",
      "1580 - [UK]\n",
      "1599 - [UK] - Drunke? hees a beast and he be drunke, theres no man that is a sober man will be drunk, hees a boy and he be drunke.\n",
      "1611 - [UK] - Out, filthy beast, I loath thy lookes, / And hate thee like a toad.\n",
      "1619 - [UK]\n",
      "1642 - [UK]\n",
      "1673 - [UK]\n",
      "1678 - [UK]\n",
      "1703 - [UK]\n",
      "1727 - [UK]\n",
      "1731 - [UK] - They call me Old Fool, and drunken old Beast to my Face.\n",
      "1821 - [UK] - Dull beast! replied Varney.\n",
      "1837 - [UK]\n",
      "1862 - [UK]\n",
      "1873 - [UK] - Look at him! [...] did you ever see such a Beast as he looks?\n",
      "1896 - [UK] - I never hated anyone that I know of, but I do hate him now. Hes a beast.\n",
      "1906 - [UK] - Sproggs you beast!\n",
      "1913 - [UK] - Damn old Brownjohn, growled Michael. I think hes the damnedest old beast that ever lived..\n",
      "1917 - [UK]\n",
      "1922 - [US]\n",
      "1933 - [US] - Josephine, I forbid you to speak to that beast of a man.\n",
      "1947 - [UK] - Scruffy little beast, shiny blue suit, looked pretty shady all told.\n",
      "1958 - [US] - I mean hes sweet when he isnt drunk, but let him start lapping up the vino, and oh God quel beast!\n",
      "1968 - [UK]\n",
      "1986 - [UK]\n",
      "2008 - [UK]\n",
      "a bicycle [synon. with SE , a horse\n",
      "1898 - [UK] - [T]he vicious beast of a bicycle, seeing its opportunity, shied suddenly to one side.\n",
      "1909 - [UK]\n",
      "a fast car\n",
      "1954 - [US] - Beast, n. A car.\n",
      "1958 - [US] - Your jalopys no real beast, O.K.\n",
      "1961 - [US] - Beep beep to all you handcuffs whose teenagers fizz it up when you wont let them have the beast.\n",
      "the 2 train, part of the IRT subway sustem in NYC\n",
      "1982 - [US]\n",
      "2017 - [US]\n",
      "a child molester, a sexual offender\n",
      "1877 - [UK] - A Beast James Blizzard [...] was charged with having committed an indecent assault upon Agnes Holbrook].\n",
      "1983 - [UK]\n",
      "1990 - [UK]\n",
      "1998 - [UK] - Thirs loads ay beasts oan the wing, but only one in the whole ay the Scottish prison system that they call the Beast.\n",
      "2012 - [UK] - So ah slips intae Albos cell [...] n sees the Beast jist sittin thaire.\n",
      "2014 - [UK]\n",
      "cheap beer\n",
      "1987 - [US] - beast Milwaukees Best, inexpensive brand of beer: We only had five dollars so we bought Beast.\n",
      "2004 - [US]\n",
      "an expert, an outstanding example\n",
      "2012 - [US] - BEAST someone who is exceptionally good at something: Michael Phelps is a beast at swimming.\n",
      "a young woman, esp. an unattractive but sexually voracious one\n",
      "1934 - [US]\n",
      "1948 - [US] - Beast. Distasteful female.\n",
      "1950 - [US] - Beast. A prostitute or lewd woman.\n",
      "1955 - [US] - beast [...] n. Woman of loose morals.\n",
      "1957 - [US] - Whats the matter [...] the beast dont move you?\n",
      "1960 - [US] - beast A cheap prostitute or B-girl.\n",
      "any unattractive young woman\n",
      "1950 - [US] - Beast. [...] a very homely or slatternly woman.\n",
      "1953 - [US] - Confidentially I know she looks like a beast.\n",
      "1967 - [US]\n",
      "1975 - [US] - She was there with another girl [...] a beast who had pimples and wore glasses.\n",
      "1980 - [US] - Other derogatory terms for women liken their unattractiveness to animals [...] Terms like [...] beast, bat, and boogabear.\n",
      "a girlfriend viewed in a sexual context, esp. when she has another established relationship already\n",
      "1946 - [US] - The last time I was there, that was a year ago, man, I found a fine little beast. Cutest little doll you ever saw, blonde, a beautiful figure, really a beautiful girl.\n",
      "1957 - [US] - That beast of yours doesnt think so. [Ibid.] Man, dig that crazy [rump] on the big beast in the plaid skirt!\n",
      "heroin; thus heroin addiction\n",
      "1958 - [US] - His clothes were tattered, but that didnt matter / Not to Sam, at least, / As long as Mable his whore was able / To satisfy his beast.\n",
      "1970 - [US] - I knew the Beast when I saw him, though [...] The Beast was dope.\n",
      "1983 - [US]\n",
      "2001 - [US] - Beast Heroin. [Ibid.] The beast Heroin.\n",
      "LSD\n",
      "1969 - [US] - beast, the [...] LSD-25.\n",
      "1982 - [US] - A sampling of current names for varieties of LSD would include [...] beast.\n",
      "2001 - [US] - Beast [...] LSD.\n",
      "a white person\n",
      "1968 - [US]\n",
      "1969 - [US]\n",
      "1978 - [US] - Been bleedin Whiteys war. Killin brown folks, ain no reason. Been dyin fo the Beast.\n",
      "1980 - [US] - Expressions like [...] beast (white person), fronts (suit of clothes), gunny (marijuana) [...] have been common currency among blacks for some time.\n",
      "1990 - [US] - He leans down into the Beavers face and grunts. The Joker knows that you the beast because the Joker is a blue-eyed soul brother..\n",
      "the police; a police officer\n",
      "1978 - [US]\n",
      "1989 - [UK] - Beast (W.I.) a police officer.\n",
      "1992 - [UK]\n",
      "1999 - [UK] - There was no way he would let the beast know of the tribulation.\n",
      "2002 - [US] - We Words (My Favorite Things) [...] The breaks. The beast. The blues. The vapors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = [print(d) for d in data_proc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now save the pre-processed data to be used for experiments. See the notebook *Trace.ipynb* in the code package for how this can be used to reproduce results in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('GSD_sample_data.npy', data_proc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
